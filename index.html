<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Audio Recorder (WAV)</title>
  <!-- TailwindCSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <!-- Recorder.js (WAV recording) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/recorderjs/0.1.0/recorder.min.js"></script>
  <style>
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.5; }
      100% { opacity: 1; }
    }
    .recording-animation {
      animation: pulse 1.5s infinite;
    }
    .waveform {
      height: 60px;
      display: flex;
      align-items: flex-end;
      justify-content: center;
      gap: 3px;
    }
    .wave-bar {
      width: 4px;
      background-color: #3B82F6;
      border-radius: 2px;
      transition: height 0.1s ease;
      height: 10px;
    }
    .response-audio {
      width: 100%;
      margin-top: 10px;
    }
  </style>
</head>
<body class="bg-gray-100 min-h-screen flex flex-col items-center justify-center p-4">
  <div class="bg-white rounded-xl shadow-lg p-6 w-full max-w-md">
    <h1 class="text-2xl font-bold text-center text-gray-800 mb-6">Audio Recorder</h1>
    <div class="mb-6">
      <div id="permissionStatus" class="hidden mb-4 p-3 rounded-lg text-sm"></div>
      <div id="waveform" class="waveform hidden">
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
        <div class="wave-bar"></div>
      </div>
      <div id="audioPlayerContainer" class="hidden mt-4">
        <audio id="audioPlayer" controls class="w-full"></audio>
      </div>
    </div>

    <div class="flex flex-col space-y-4">
      <button id="recordButton" class="bg-blue-500 hover:bg-blue-600 text-white py-3 px-6 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors">
        <i class="fas fa-microphone"></i>
        <span id="recordLabel">Start Recording</span>
      </button>
      <button id="sendButton" disabled class="bg-green-500 hover:bg-green-600 text-white py-3 px-6 rounded-lg font-medium flex items-center justify-center space-x-2 transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
        <i class="fas fa-paper-plane"></i>
        <span>Send to API</span>
      </button>

      <div id="apiResponse" class="hidden mt-4 p-4 bg-gray-50 rounded-lg border border-gray-200">
        <h3 class="font-medium text-gray-700 mb-2">API Response:</h3>
        <div id="responseText" class="text-sm text-gray-600 mb-2"></div>
        <audio id="responseAudio" controls class="response-audio hidden"></audio>
      </div>
    </div>

    <!-- Text result history -->
    <div id="historyContainer" class="mt-4 bg-gray-100 p-4 rounded-md">
      <h3 class="text-lg font-semibold mb-2">Text Results History</h3>
      <div id="historyContent" class="space-y-2"></div>
    </div>
  </div>

  <div id="statusToast" class="fixed bottom-4 left-1/2 transform -translate-x-1/2 bg-gray-800 text-white px-4 py-2 rounded-lg shadow-lg opacity-0 transition-opacity duration-300"></div>

  <script>
    // Global variables
    let recorder;
    let audioStream;
    let audioBlob;
    let recording = false;
    let audioContext;
    let analyser;
    let animationFrameId;
    const waveBars = document.querySelectorAll('.wave-bar');

    // API Path flow variables (example as previous)
    let currentPath = "maincommand";
    let stepIndex = 0;
    let pathSteps = [];

    // History for text results
    const resultsHistory = [];

    // DOM elements
    const recordButton = document.getElementById('recordButton');
    const recordLabel = document.getElementById('recordLabel');
    const sendButton = document.getElementById('sendButton');
    const audioPlayer = document.getElementById('audioPlayer');
    const audioPlayerContainer = document.getElementById('audioPlayerContainer');
    const waveform = document.getElementById('waveform');
    const permissionStatus = document.getElementById('permissionStatus');
    const apiResponse = document.getElementById('apiResponse');
    const responseText = document.getElementById('responseText');
    const responseAudio = document.getElementById('responseAudio');
    const statusToast = document.getElementById('statusToast');
    const historyContent = document.getElementById('historyContent');

    // Check for microphone permission with improved constraints
    async function checkMicrophonePermission() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 44100,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        stream.getTracks().forEach(track => track.stop());
        permissionStatus.classList.remove('hidden', 'bg-red-100', 'text-red-700');
        permissionStatus.classList.add('bg-green-100', 'text-green-700');
        permissionStatus.innerHTML = '<i class="fas fa-check-circle mr-2"></i> Microphone access granted';
      } catch (error) {
        permissionStatus.classList.remove('hidden', 'bg-green-100', 'text-green-700');
        permissionStatus.classList.add('bg-red-100', 'text-red-700');
        permissionStatus.innerHTML = '<i class="fas fa-exclamation-circle mr-2"></i> Microphone access denied. Please allow microphone access to use this app.';
        recordButton.disabled = true;
      }
      permissionStatus.classList.remove('hidden');
    }

    // Setup API path flow (unchanged from your original logic)
    function resetApiPath() {
      currentPath = "maincommand";
      stepIndex = 0;
      pathSteps = [];
    }
    function setupPathFlow(command) {
      switch (command) {
        case "cardtocard":
          pathSteps = ["number", "number", "number"];
          break;
        case "Internetpackage":
          pathSteps = ["number", "type/internet"];
          break;
        case "cashtransfer":
          pathSteps = ["type/cashtransfer", "number", "number", "number"];
          break;
        default:
          pathSteps = [];
      }
      stepIndex = 0;
    }

    // Show toast messages
    function showToast(message, type) {
      statusToast.textContent = message;
      statusToast.classList.remove('bg-gray-800', 'bg-green-500', 'bg-red-500', 'bg-blue-500');
      switch (type) {
        case 'success': statusToast.classList.add('bg-green-500'); break;
        case 'error': statusToast.classList.add('bg-red-500'); break;
        case 'info': statusToast.classList.add('bg-blue-500'); break;
        default: statusToast.classList.add('bg-gray-800');
      }
      statusToast.classList.remove('opacity-0');
      statusToast.classList.add('opacity-100');
      setTimeout(() => {
        statusToast.classList.remove('opacity-100');
        statusToast.classList.add('opacity-0');
      }, 3000);
    }

    // Animate waveform using AnalyserNode data
    function animateWaveform() {
      if (!analyser) return;
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteTimeDomainData(dataArray);
      
      // Compute a simple "volume" level
      let sum = 0;
      dataArray.forEach(val => sum += Math.abs(val - 128));
      const average = sum / dataArray.length;
      
      // Update each bar's height based on the average volume plus some random fluctuation
      waveBars.forEach(bar => {
        // Scale the height value (minimum 10px, maximum ~50px)
        const height = Math.min(50, Math.max(10, average + (Math.random()*10 - 5)));
        bar.style.height = height + 'px';
      });
      animationFrameId = requestAnimationFrame(animateWaveform);
    }

    // Start recording with Recorder.js
    async function startRecording() {
      // Add a 1-second countdown before starting
      recordLabel.textContent = 'Get Ready...';
      await new Promise(resolve => setTimeout(resolve, 1000));

      try {
        audioStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 44100,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        // Initialize AudioContext and connect the stream
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const input = audioContext.createMediaStreamSource(audioStream);
        // Setup analyser for real-time feedback
        analyser = audioContext.createAnalyser();
        input.connect(analyser);

        // Initialize Recorder.js (mono recording)
        recorder = new Recorder(input, { numChannels: 1 });
        recorder.record();
        recording = true;
        recordButton.classList.add('bg-red-500', 'hover:bg-red-600', 'recording-animation');
        recordButton.classList.remove('bg-blue-500', 'hover:bg-blue-600');
        recordLabel.innerHTML = '<i class="fas fa-stop mr-2"></i> Stop Recording';
        waveform.classList.remove('hidden');
        animateWaveform();
        showToast('Recording started', 'info');
      } catch (error) {
        console.error('Error starting recording:', error);
        showToast('Failed to start recording', 'error');
      }
    }

    // Stop recording and export WAV
    function stopRecording() {
      if (recorder && recording) {
        recorder.stop();
        // Stop audio tracks
        audioStream.getTracks().forEach(track => track.stop());
        // Stop the waveform animation
        cancelAnimationFrame(animationFrameId);
        waveBars.forEach(bar => bar.style.height = '10px');
        waveform.classList.add('hidden');
        recording = false;
        recordButton.classList.remove('bg-red-500', 'hover:bg-red-600', 'recording-animation');
        recordButton.classList.add('bg-blue-500', 'hover:bg-blue-600');
        recordLabel.innerHTML = '<i class="fas fa-microphone mr-2"></i> Start Recording';
        
        // Export the WAV audio blob
        recorder.exportWAV(blob => {
          audioBlob = blob;
          const audioUrl = URL.createObjectURL(blob);
          audioPlayer.src = audioUrl;
          audioPlayerContainer.classList.remove('hidden');
          sendButton.disabled = false;
        });
      }
      showToast('Recording stopped', 'info');
    }

    // Event listener for record button
    recordButton.addEventListener('click', () => {
      if (recording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    // Send recording to API
    sendButton.addEventListener('click', async () => {
      if (!audioBlob) {
        showToast('No recording to send', 'error');
        return;
      }
      try {
        sendButton.disabled = true;
        sendButton.innerHTML = '<i class="fas fa-spinner fa-spin mr-2"></i> Sending...';
        const formData = new FormData();
        formData.append('voice', audioBlob, 'recording.wav');
        const response = await fetch(`https://your-api-endpoint/${currentPath}`, {
          method: 'POST',
          body: formData
        });
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const textResult = response.headers.get('result');
        const audioBytes = await response.blob();
        apiResponse.classList.remove('hidden');
        responseText.textContent = textResult || 'No text result received';
        addResultToHistory(textResult);
        if (audioBytes.size > 0) {
          const audioUrl = URL.createObjectURL(audioBytes);
          responseAudio.src = audioUrl;
          responseAudio.classList.remove('hidden');
        } else {
          responseAudio.classList.add('hidden');
        }
        // Update API path (logic from your original code)
        if (currentPath === "maincommand") {
          setupPathFlow(textResult);
          if (pathSteps.length > 0) {
            currentPath = pathSteps[stepIndex++];
          }
        } else if (stepIndex < pathSteps.length) {
          currentPath = pathSteps[stepIndex++];
        } else {
          resetApiPath();
        }
        showToast('Recording sent successfully!', 'success');
      } catch (error) {
        console.error('Error sending to API:', error);
        responseText.textContent = 'Error: ' + error.message;
        apiResponse.classList.remove('hidden');
        showToast('Failed to send recording', 'error');
        resetApiPath();
      } finally {
        sendButton.disabled = false;
        sendButton.innerHTML = '<i class="fas fa-paper-plane mr-2"></i> Send to API';
      }
    });

    // Add result to history
    function addResultToHistory(text) {
      resultsHistory.push(text);
      const historyItem = document.createElement('div');
      historyItem.classList.add('bg-white', 'p-2', 'rounded-md', 'shadow-md');
      historyItem.textContent = text;
      historyContent.insertBefore(historyItem, historyContent.firstChild);
    }

    // Check microphone permission on load
    document.addEventListener('DOMContentLoaded', checkMicrophonePermission);
  </script>
</body>
</html>